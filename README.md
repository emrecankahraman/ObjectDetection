# ğŸ§  Object Detection Web App

Detects objects in uploaded images, analyzes dominant colors, and stores this data in Elasticsearch, allowing users to search based on labels, color, and city. Built with a modern Clean Architecture approach using .NET, the application communicates with an external AI service via HTTP to deliver powerful image analysis capabilities.

---

## ğŸš€ Project Goal

This application manages an end-to-end process starting from image upload:

1. An image is uploaded.
2. It is sent to an external AI service via HTTP POST.
3. The returned analysis results are stored in both a database and Elasticsearch.
4. Users can search images using label and color information.

---

## ğŸ§± Architecture Overview (Clean Architecture)

```
ObjectDetection/
â”œâ”€â”€ Core/
â”‚   â”œâ”€â”€ Application     â†’ UseCases, DTOs, service contracts
â”‚   â””â”€â”€ Domain          â†’ Entities and core business rules
â”œâ”€â”€ Infrastructure/
â”‚   â”œâ”€â”€ Infrastructure  â†’ External integrations such as AI service
â”‚   â””â”€â”€ Persistence     â†’ EF Core-based data access
â”œâ”€â”€ Presentation/       â†’ .NET interface
â””â”€â”€ docker/
    â””â”€â”€ docker-compose.yml â†’ Elasticsearch + Kibana
```

---

## ğŸ›  Technologies Used

* âœ… .NET 9 
* âœ… Entity Framework Core + MS SQL Server
* âœ… Clean Architecture principles
* âœ… HTTP-based AI service integration
* âœ… Elasticsearch 7.17 + Kibana
* âœ… Docker Compose (for Elastic stack)

---

## âš™ï¸ Setup

### ğŸ”½ 1. Clone the Project from GitHub

```bash
git clone https://github.com/emrecankahraman/ObjectDetection.git
cd ObjectDetection
```

> You can open the project using Visual Studio or Rider.

### 2. Requirements

* [.NET 9 SDK](https://dotnet.microsoft.com/en-us/download/dotnet/9.0)
* [Docker Desktop](https://www.docker.com/products/docker-desktop)
* A working instance of MS SQL Server

### 2. Start Elasticsearch + Kibana

```bash
cd docker
docker-compose up -d
```

* Elasticsearch: [http://localhost:9200](http://localhost:9200)
* Kibana: [http://localhost:5601](http://localhost:5601)

### 3. Database Setup

Before creating migrations, remove any previous migration folders if they exist:

```bash
# Delete the Migrations folder under ObjectDetection.Persistence
```

To create and apply a new migration:

```bash
dotnet ef migrations add InitialCreate -p ObjectDetection.Persistence -s ObjectDetection.Presentation
dotnet ef database update -p ObjectDetection.Persistence -s ObjectDetection.Presentation
```

### 4. Run the Application

```bash
cd ObjectDetection.Presentation
dotnet run
```

ğŸ“Œ The connection string in `appsettings.json` should be configured like this:

```json
"ConnectionStrings": {
  "DefaultConnection": "yourConnectionString"
}
```

Ensure this connection string matches your local SQL Server instance.

---

## ğŸ§ª Application Flow

1. ğŸ‘¤ Register / Login
2. ğŸ“¤ Upload an image
3. ğŸ” The image is sent to an external AI service via HTTP
4. ğŸ§  Detected objects and colors are stored in:

   * The database (via EF Core)
   * Elasticsearch (for search functionality)
5. ğŸ” Example search queries:

   * "white car istanbul"
   * "black dog"

---

## ğŸ§  How the AI Service Works

The uploaded image is sent to an external AI service via the `FlaskAIClient` class. The service:

 * Location Extraction (if available): The service first checks the imageâ€™s EXIF metadata for GPS coordinates. If found, it extracts geolocation details such as country, city, state, and street.

* OpenCV Conversion: The image is decoded and processed using OpenCV.

* Preprocessing: preprocess_image() enhances the image's color saturation to improve detection and color accuracy.

* Object Detection: TensorFlowâ€™s Faster R-CNN model is used to detect objects within the image.

* Cropping: Detected objects are cropped individually from the original image.

* Background Removal: Each cropped object is sent to the remove.bg API to remove the background.

* Dominant Color Analysis: KMeans clustering is applied to the masked and preprocessed image to determine the dominant color for each object.

* Result Output: The final results, including detected classes, confidence scores, dominant colors, and location information, are returned as a structured JSON.

This communication is done via `HTTP POST`. The response is parsed into `DetectionResultDto` objects and stored in both the database and Elasticsearch.

ğŸ”— For the source code of the AI service: [object-detection-ai](https://github.com/emrecankahraman/ObjectDetectionPythonProject)

---

## ğŸ³ Docker Content

`docker/docker-compose.yml` is used to run Elasticsearch and Kibana:

```yaml
elasticsearch:
  image: elasticsearch:7.17.10
  ports: ["9200:9200"]

kibana:
  image: kibana:7.17.10
  ports: ["5601:5601"]
```

---

## ğŸ“Œ AI Service Configuration

The AI service endpoint is defined within the `FlaskAIClient` class in code. The default URL is:

```csharp
var url = _configuration["AIService:Url"] ?? "http://127.0.0.1:5000/predict";
```

You can override this by defining `AIService:Url` in `appsettings.json`. Otherwise, the default address will be used.

---

## ğŸ“„ License

This project is licensed under the [MIT License](https://opensource.org/licenses/MIT).
